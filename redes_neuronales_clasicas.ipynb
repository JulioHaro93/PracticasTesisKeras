{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOTB/gGDzr6mjnGiGG5NEd4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JulioHaro93/PracticasTesisKeras/blob/main/redes_neuronales_clasicas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "mq9eRKux8oyC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14bdd040-8412-4cec-cea3-055839d715ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow==2.12 in /usr/local/lib/python3.11/dist-packages (2.12.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (25.2.10)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (1.71.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (3.13.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (0.4.30)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (18.1.1)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (4.25.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (1.17.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (2.12.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (4.13.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow==2.12) (0.45.1)\n",
            "Requirement already satisfied: jaxlib<=0.4.30,>=0.4.27 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow==2.12) (0.4.30)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow==2.12) (0.4.1)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow==2.12) (1.15.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (2.38.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (3.8)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (3.1.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12) (4.9.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12) (2.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12) (2025.4.26)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow==2.12) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow==2.12"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-datasets\n",
        "!pip install tensorflow.keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZlMIl_sAnnw",
        "outputId": "ea06eb84-92f9-45a8-e353-48c303850e0b"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.11/dist-packages (4.9.8)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (1.4.0)\n",
            "Requirement already satisfied: array_record>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (0.7.2)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (0.1.9)\n",
            "Requirement already satisfied: etils>=1.9.1 in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets) (1.12.2)\n",
            "Requirement already satisfied: immutabledict in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (4.2.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (1.23.5)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (2.3)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (4.25.7)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (5.9.5)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (18.1.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (2.32.3)\n",
            "Requirement already satisfied: simple_parsing in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (0.1.7)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (1.17.1)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (3.1.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (0.10.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (4.67.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (1.14.1)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets) (0.8.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets) (2025.3.2)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets) (6.5.2)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets) (4.13.2)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets) (3.21.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->tensorflow-datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->tensorflow-datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->tensorflow-datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->tensorflow-datasets) (2025.4.26)\n",
            "Requirement already satisfied: attrs>=18.2.0 in /usr/local/lib/python3.11/dist-packages (from dm-tree->tensorflow-datasets) (25.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from promise->tensorflow-datasets) (1.17.0)\n",
            "Requirement already satisfied: docstring-parser<1.0,>=0.15 in /usr/local/lib/python3.11/dist-packages (from simple_parsing->tensorflow-datasets) (0.16)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.56.4 in /usr/local/lib/python3.11/dist-packages (from tensorflow-metadata->tensorflow-datasets) (1.70.0)\n",
            "Requirement already satisfied: tensorflow.keras in /usr/local/lib/python3.11/dist-packages (0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-ecEKcEtAmxt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importaciones necesarias"
      ],
      "metadata": {
        "id": "QHIiXZfEAVt8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime"
      ],
      "metadata": {
        "id": "_vfItLdJAY2v"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vvZJY89fBP4O"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Pre procesado de datos para que puedan ser tratadas las imágenes de manera correcta"
      ],
      "metadata": {
        "id": "4LJs3_jgBjmA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Cargar dataset\n",
        "(X_train, Y_train), (X_test, Y_test) = fashion_mnist.load_data()"
      ],
      "metadata": {
        "id": "Yi9WjaHABsKU"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Normalizar imágenes\n",
        "\n",
        "Siempre es recomendado escalar de 0 a 1 para que converja más rápidamente, por eso dividimos entre el valor del pixel más alto\n",
        "\n"
      ],
      "metadata": {
        "id": "uny_lG2NJ3Xv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train/255.0\n",
        "X_test = X_test/255.0"
      ],
      "metadata": {
        "id": "e2JMbPDZJ68f"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Redimensionamos el dataset\n",
        "Ahora sí que aplanamos el dataset"
      ],
      "metadata": {
        "id": "dTV71VlUKz4H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Considerar las dimensiones de todas las imágenes  que tienen en este caso 28 x 28\n",
        "# hacemos un reshape [-1, todos los elementos, anchura * altura]\n",
        "\n",
        "X_train = X_train.reshape(-1,28*28)\n",
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJHRddclKy2O",
        "outputId": "ea50799a-aa0a-4e26-de19-801a3facf3aa"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Una vez que aplanamos, ahora podemos construir el modelo con tensorflow2.0\n",
        "\n"
      ],
      "metadata": {
        "id": "thNfBNFoM_zR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Primero necesitamos definir un modelo o arquitectura de la misma, esta va a ser una red clasificadora, por lo que pensamos en las capas de la red\n",
        "Hiperparámetros de la capa:\n",
        "\n",
        "\n",
        "*   Número de unidades/neuronas: 128\n",
        "*   función de activación: ReLu\n",
        "*   input_shape: (784,)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2l2b1HZbNLqr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Primer paso es usar la clase Sequential para crear el objeto del modelo\n",
        "\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "#Segundo paso se crea la primera capa totalmente conectada (Densa) con los hiperparámetros\n",
        "model.add(tf.keras.layers.Dense(units=128, activation='relu', input_shape=(784,)))\n",
        "\n"
      ],
      "metadata": {
        "id": "-IXij4S3MKpL"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#En este ejemplo se utiliza una capa de Dropout\n",
        "El dropout es una técnica de regularización donde aleatoriamente se asigman ciertas neuronas de la red el valor cero. De este modo, mientras se entrena estas neuronas no actualizan sus valores. Al tener cierpo porcentaje de neuronas sin actualizar, el proceso de entrenamiento toma más tiempo pero por contra tenemos menos posibilidades de sufrir overfitting"
      ],
      "metadata": {
        "id": "q3P6r2QYOInR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(tf.keras.layers.Dropout(0.1))"
      ],
      "metadata": {
        "id": "p_f1jFE4OHZv"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#implementamos la capa de salida, por esta razón, deben ser 10 neuronas de salida con la función softmax (probabilidad)\n",
        "\n",
        "\n",
        "*   Número de neuronas: 10 porque son 10 clases, en mi caso serán 5\n",
        "*   función de activación: softmax\n",
        "\n"
      ],
      "metadata": {
        "id": "N1g1iWE_RpjJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(tf.keras.layers.Dense(units=10, activation='softmax'))"
      ],
      "metadata": {
        "id": "22iUhr-vRng8"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Compilación del código\n",
        "Elegimos un optimizador, en este caso Adam\n",
        "las pérdias con Sárse softmax"
      ],
      "metadata": {
        "id": "JT2fNwLTSA_K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#sparse se utiliza en este caso porque no son clases binarias, sino 10 posibles categorías\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])"
      ],
      "metadata": {
        "id": "0Sqj0E8xR_Xr"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nC4KDyqTHPt",
        "outputId": "8129cc68-6ed1-4418-fb2d-f56ebf95bbe9"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_5 (Dense)             (None, 128)               100480    \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 101,770\n",
            "Trainable params: 101,770\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Fase de entrenamiento"
      ],
      "metadata": {
        "id": "ogiPOd4rTqv7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, Y_train, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JN03TYV4TqRH",
        "outputId": "16f18cf4-e986-44df-eb9c-83a9a9cfc650"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 20s 10ms/step - loss: 0.5160 - sparse_categorical_accuracy: 0.8194\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 16s 8ms/step - loss: 0.3857 - sparse_categorical_accuracy: 0.8613\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.3498 - sparse_categorical_accuracy: 0.8717\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.3290 - sparse_categorical_accuracy: 0.8785\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.3128 - sparse_categorical_accuracy: 0.8836\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.3002 - sparse_categorical_accuracy: 0.8883\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2914 - sparse_categorical_accuracy: 0.8921\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2817 - sparse_categorical_accuracy: 0.8942\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2705 - sparse_categorical_accuracy: 0.8978\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2621 - sparse_categorical_accuracy: 0.9011\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7920f9cecb50>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Evaluación del modelo y predicción"
      ],
      "metadata": {
        "id": "OYeVtOk5U-h6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = X_test.reshape(-1,28*28)\n",
        "X_test.shape\n",
        "\n",
        "test_loss, test_accuracy = model.evaluate(X_test, Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCPPkqNAVBnE",
        "outputId": "e82829ee-0e9e-4187-8805-9df165bae20a"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3394 - sparse_categorical_accuracy: 0.8797\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Test accuracy: {}\".format(test_accuracy))\n",
        "print(\"Loss: {}\".format(test_loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHcBSavdWUgu",
        "outputId": "3c8e4d58-98fe-40a8-aa85-085c59b4cad2"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.8797000050544739\n",
            "Loss: 0.33941450715065\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Guardar el modelo\n",
        "\n",
        "#Importante para la **tesis**\n",
        "\n",
        "Guardamos el modelo en formato json"
      ],
      "metadata": {
        "id": "OT1a7cLUWN0d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_json = model.to_json()\n",
        "with open(\"fashion_model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "\n",
        "#guardar  los pesos\n",
        "\n",
        "model.save_weights(\"fashion_model.h5\")"
      ],
      "metadata": {
        "id": "FjthlXqKWmYF"
      },
      "execution_count": 60,
      "outputs": []
    }
  ]
}